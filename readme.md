
# SEDyConv
This repo holds code for SEDyConv: Spatially Enhanced Multi-dimensional Dynamic Convolution for Medical Multi-organ Segmentation in CTs
## ðŸ“Œ What is This Paper About?
Automated multi-organ segmentation presents a considerable challenge owing to the diversity of organs and individual variations. Current state-of-the-art deep-learning techniques rely primarily on static kernel weights that are fixed after training, thereby limiting their flexibility in adapting to diverse inputs. In this study, we propose a novel multi-organ segmentation method using a plug-and-play three-dimensional dynamic convolution module. This method is designed to address the challenges posed by the variability of CT scans in contrast to static segmentation models. We uniquely leverage multiple input-dependent attention mechanisms to adjust the coefficients across four dimensions of convolutional kernels dynamically, offering enhanced adaptability. This approach surpasses traditional feature-based dynamic methods in terms of flexibility, which is attributable to the global sharing of kernel parameters and a smaller kernel shape. In addition, we utilize a refined local block to preserve the spatial properties and extend the convolutional kernel space to N dimensions, thereby efficiently enhancing the representational capabilities of the model through higher-dimensional feature fusion. Furthermore, we design dynamic switches to integrate multi-dimensional global and local information adaptively, guiding the model to generate feature maps that closely align with the input characteristics. Visualizations of the dynamic coefficients and features generated by different inputs clearly demonstrate the adaptability of our method. Extensive experiments on four multi-organ segmentation datasets with various labeled organs and scales indicate that our proposed method outperforms other state-of-the-art methods in terms of improving the segmentation accuracy, particularly for organs with complex morphologies or small sizes.
## Keywords
3D dynamic convolution; Attention mechanism; Medical image segmentation; Multi-organ segmentation
## Method
<p align="center">
    <img src="./imgs/fig3.png" width="100%" height="100%">
</p>
<b>Fig. 1.</b> Schematic of the convolution space on which our spatially enhanced multi-dimensional dynamic convolution (SEDyConv) operates. For clarity, consider the 2D convolution kernel and ignore the bias. (a) The output channel dimension; that is, the number of filter dimensions, (b) the input channel dimension, (c) the 2D spatial dimension of all filters, and (d) the 3D kernel space dimension of one filter. We first compute four type weights &alpha;<SUB>f</SUB>, &alpha;<SUB>c</SUB>, &alpha;<SUB>sf</SUB> and &alpha;<SUB>sc</SUB> for the original kernel W. Then, we dynamically combine the processed  with switches to generate the final \hat{W}. During this process, weights  and  are used to preserve the spatial properties and expand the convolutional kernel space into N dimensions. The formulations and implementations are clarified in the Methodology section.

## Architecture
# SEDy-nnUNet


# SEDy-Unetr
